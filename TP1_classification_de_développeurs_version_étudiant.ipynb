{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Qu'allons nous faire dans ce TP ? üèó\n",
    "\n",
    "Ce TP est l√† pour vous montrer que des probl√©matiques GL peuvent √™tre en partie solutionn√©es par des solutions d'IA. Un exemple d'IA pour le GL que vous connaissez s√ªrement est [Github CoPilot](https://github.com/features/copilot/) (suggestion de code bas√©e sur des exemples Github). Ainsi, ce premier TP va vous montrer comment pr√©dire le nombre de d√©veloppeurs exp√©riment√© pour un projet en fonction de la taille de ce dernier. Cet exemple est issu de nos travaux de recherche, la r√©f√©rence du papier de recherche est ici : \n",
    "\n",
    "\n",
    "\n",
    "*   *Quentin Perez, Christelle Urtado, Sylvain Vauttier. Mining Experienced Developers in Open-source Projects. ENASE 2022 - 17th International Conference on Evaluation of Novel Approaches to Software Engineering, Apr 2022, Online, France. pp.443-452*\n",
    "*   URL vers le papier: [https://hal.mines-ales.fr/hal-03654959/document](https://hal.mines-ales.fr/hal-03654959/document)\n",
    "\n",
    "\n",
    "Nous ferons √©galement un peu de *data science*/statistiques pour vous montrer au travers de deux petits exemples √† quoi cela peut servir.\n",
    "Cependant attention, l'IA ü§ñ n'est pas non plus Merlin l'Enchanteur üßô et ne peut donc pas aller au-del√† de ses capacit√©s. Elle est fortement d√©pendante du type d'apprentissage, de la m√©thode d'apprentissage et des donn√©es d'entr√©es. "
   ],
   "metadata": {
    "id": "JN0T92xSMGY0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pr√©requis pour l'utilisation du notebook Colab **üì¶**"
   ],
   "metadata": {
    "id": "Yfymgkt98NWH",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ‚ö† AVANT TOUTES MANIPULATIONS : FAIRE COPIE DE CE NOTEBOOK COLAB DANS VOTRE ESPACE GOOGLE\n",
    "\n",
    "Pour ce faire aller sur le menu \"Fichier\" puis \"Enregistrer une copie dans Drive\""
   ],
   "metadata": {
    "id": "SWxer9RZN6dg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Cr√©ation de dossiers sur votre Google Drive\n",
    "\n",
    "‚ö† Vous devez imp√©rativement cr√©er √† la racine de votre Google Drive le dossier \"`TP_IAGL`\" puis √† l'int√©rieur de celui-ci cr√©er les dossiers \"`ck_metrics`\" et \"`metrics_by_dev`\"."
   ],
   "metadata": {
    "id": "uqturraVTQB3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Montage de votre Google Drive sur l'instance **Colab**\n",
    "\n",
    "üíæ La cellule *de* code plus bas va vous permettre de vous connecter √† votre Google Drive afin de sauvegarder l'ensemble des √©l√©ments manipul√©s dans ce TP. Le lien pour acc√©der au dossier \"`TP_IAGL`\" sera <code>/content/drive/MyDrive/TP_GLIA</code> "
   ],
   "metadata": {
    "id": "mLfwx6GFUN29",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "FJJAoVyZPHZb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation des biblioth√®ques et t√©l√©chargement des fichiers"
   ],
   "metadata": {
    "id": "RlcFnBw-8e4P",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons besoin de GitPython afin de manipuler des d√©p√¥ts Git avec Python. La commande Colab ci dessous permet de l'installer. "
   ],
   "metadata": {
    "id": "0RjVCo4vLIKU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gitpython"
   ],
   "metadata": {
    "id": "_Dy2AwjZK8Fp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "R√©cup√©ration des diff√©rents fichiers de donn√©es n√©cessaires au TP depuis Github en utilisant wget."
   ],
   "metadata": {
    "id": "G8Pz3YBqLNsL",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -N https://github.com/qperez/TP-Master-MTP-GL-IA4GL/raw/main/ck_metrics/ck.jar -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://github.com/qperez/TP-Master-MTP-GL-IA4GL/raw/main/classifier_rf.pkl -P /content/drive/MyDrive/TP_GLIA/\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/dataset_dev_anonymized.csv -P /content/drive/MyDrive/TP_GLIA\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-1.6.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-2.0.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-2.1.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-2.2.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-2.3.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-2.4.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-3.0.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-3.1.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-4.0.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-4.1.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-5.0.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/ck_metrics/class_broadleaf-5.1.0-GA.csv -P /content/drive/MyDrive/TP_GLIA/ck_metrics\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-1.6.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-2.0.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-2.1.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-2.2.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-2.3.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-2.4.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-3.0.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-3.1.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-4.0.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-4.1.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-5.0.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-5.1.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-5.2.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-6.0.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n",
    "!wget -N https://raw.githubusercontent.com/qperez/TP-Master-MTP-GL-IA4GL/main/metrics_by_dev/broadleaf-1.5.0-GA_broadleaf-6.1.0-GA_aggregated.csv -P /content/drive/MyDrive/TP_GLIA/metrics_by_dev\n"
   ],
   "metadata": {
    "id": "rM9TbbS4Dox9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import des lib n√©cessaires au Notebook."
   ],
   "metadata": {
    "id": "_DAOxOMjDTyj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhNhJ5IqDeVS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import glob\n",
    "from git import Repo, Git\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "wFlp_rAPDeVV"
   },
   "source": [
    "## Ex√©cution des cellules n√©cessaires au TP\n",
    "\n",
    "Fonction permettant de supprimer les colonnes inutiles dans le jeu de donn√©es de d√©veloppeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AR2WqrSIDeVZ"
   },
   "outputs": [],
   "source": [
    "# Prend un dataframe Pandas en param√®tre\n",
    "def delete_unused_columns(df):\n",
    "    columns_to_drop = [\"name\", \"followers\", \"commit_count_a\", \"source\", \"job\", \"name_without_spaces\", \"from\", \"to\",\n",
    "                       \"project\", \"index\", \"AddSM\",\"DelSM\",\"ChurnSM\",\"SumAddDelSM\",\"SumAddDel\"]\n",
    "\n",
    "    for column_to_drop in columns_to_drop:\n",
    "        if column_to_drop in df.columns :\n",
    "            df.drop(columns=[column_to_drop], inplace=True)\n",
    "\n",
    "    df[\"DiP\"] = df[\"DiP\"].round()\n",
    "    df[\"DiP\"].replace(0, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj97pwxNDeVa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fonction permettant d'appliquer un logarithme les colonnes du jeu de donn√©es de d√©veloppeurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jgowxyxgDeVc"
   },
   "outputs": [],
   "source": [
    "# Prend un dataframe Pandas en param√®tre\n",
    "def log_dataframe(df):\n",
    "\n",
    "    columns_4_log = [\"SumAddDelLOC\", \"DiP\", \"NoC\", \"SumAddDelF\",\n",
    "                     \"SumAddDelSAM\", \"AddLOC\", \"DelLOC\", \"AddSAM\", \"DelSAM\"]\n",
    "\n",
    "    for column in columns_4_log:\n",
    "        df[column] = np.log(df[column] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# D√©but du TP üöÄ"
   ],
   "metadata": {
    "id": "qa1oWllQQ8Jd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SAv7l8HDeVe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1) R√©cup√©ration des m√©triques de BroadleafCommerce üß≤\n",
    "\n",
    "Nous travaillerons avec les versions majeures et mineures (voir [semantic versioning](https://semver.org/lang/fr/)) du projet BroadleafCommerce disponible sur GitHub : [https://github.com/BroadleafCommerce/BroadleafCommerce](https://github.com/BroadleafCommerce/BroadleafCommerce). Pour cela, nous allons cloner le d√©p√¥t puis r√©cup√©rer les tags des versions et les filtrer par une expression r√©guli√®re. Puis, pour chacun de ces tags, \"checkouter\" la version correspondante. Nous lancerons ensuite l'extraction des m√©triques √† l'aide de l'application Java : ck ([https://github.com/mauricioaniche/ck](https://github.com/mauricioaniche/ck)). Cette application cr√©√©e par Maur√≠cio Aniche est d√©di√©e √† l'extraction de plusieurs m√©triques logicielles dont le nombre de lignes de code que nous utiliserons plus tard. \n",
    "\n",
    "Dans ce TP, nous allons extraire \"manuellement\" m√©triques mais, les plateformes d'int√©gration continue comme Jenkins ou les outils d'analyse statique comme SonarQube permettent de calculer des m√©triques de mani√®re automatique √† chaque version releas√©e ou commit√©e sur votre syst√®me de gestion de versions. \n",
    "\n",
    "\n",
    "Pour notre cas d'√©tude, nous allons : \n",
    "\n",
    "1. Utiliser le package GitPython et sa [documentation](https://gitpython.readthedocs.io/en/stable/)) pour :\n",
    "\n",
    "* Cloner le d√©p√¥t Github de BroadleafCommerce √† l'endroit indiqu√© par la variable <code> PATH_TO_REPO </code> √† l'aide de la m√©thode <code> Repo.clone_from </code>\n",
    "* Cr√©er un objet <code> Repo </code> qui vous permettra de r√©cup√©rer les tags des versions\n",
    "* Cr√©er un objet <code> Git </code> qui vous permettra de \"checkouter\" la version d√©sir√©e\n",
    "\n",
    "2.¬†R√©cup√©rer la liste des tags du d√©p√¥t √† l'aide de l'objet <code> Repo </code>.\n",
    "\n",
    "3. It√©rer sur la liste des tags, o√π pour chaque tag vous allez : \n",
    "\n",
    "* V√©rifier par une regexp que l'on se situe sur des tags ayant la forme <code> broadleaf-X-Y-0-GA </code> o√π <code> X </code> et <code> Y </code> peuvent varier entre 0 et 9 et o√π le tag a une taille fixe (utilisation de ^ et $ pour mat√©rialiser le d√©but et la fin de chaine de caract√®res)\n",
    "* Exclure les version <code>1.5.0</code> et <code>6.2.0</code>, nous n'en aurons pas besoin dans ce TP.\n",
    "* V√©rifier que l'on ne va pas extraire les m√©triques d'une version d√©j√† pr√©sente dans le dossier <code> ck_metrics </code>\n",
    "* **/!\\ Une fois ces v√©rifications effectu√©es,** checkouter la version d√©sir√©e √† l'aide du tag\n",
    "* Lancer l'extraction des m√©triques √† l'aide de l'instruction Colab suivante : <code> !java -jar /content/drive/MyDrive/TP_GLIA/ck_metrics/ck.jar /content/BroadleafCommerce false 0 false </code>\n",
    "* Renommer le fichier <code> class.csv </code> en <code> class_[tag].csv </code> et supprimer les fichiers <code> variable.csv, methode.csv, field.csv </code> cr√©√©s par ck. \n",
    "\n",
    "**Il est normal que le processus d'extraction prenne une dizaine de minutes car nous analysons l'ensemble des fichiers Java de chaque version du projet. N'h√©sitez pas √† printer pour connaitre l'op√©ration actuellement effectu√©e**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1SBvDXuDeVg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_REPO = \"/content/BroadleafCommerce\" #Ne pas modifier cette URL\n",
    "# Nous stockons les fichiers de code de BroadleafCommerce directement sur le disque de l'instance colab\n",
    "# et pas sur le Drive Google pour des questions d'espace disque mais surtout de temps de\n",
    "# calcul avec CK. CK fait de nombreuses op√©rations de lecture ce qui est extr√™mment couteux \n",
    "# √† faire directemment sur le point de montage du Drive Google.\n",
    "\n",
    "#Cr√©er les objets Git et repo ici avant l'instruction change directory\n",
    "\n",
    "wd_notebook = os.getcwd()\n",
    "os.chdir(\"/content/drive/MyDrive/TP_GLIA/ck_metrics\")\n",
    "\n",
    "#Placer l'ensemble du code n√©cessaire √† l'extraction ici\n",
    "\n",
    "os.chdir(wd_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "50NacSGA9pRE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hmNhY_PDeVj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2) Utilisation du classifieur de d√©veloppeurs (Random Forest üå≤)\n",
    " \n",
    "Nous allons maintenant utiliser le classifieur de d√©veloppeurs sauvegard√© sous le nom \"classifier_rf.pkl\" dont le chemin d'acc√®s est : `/content/drive/MyDrive/TP_GLIA/classifier_rf.pkl` . Pour cela nous allons charger le classifieur √† l'aide de <code> joblib.load </code> ([documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.load.html))\n",
    "\n",
    "2. Nous allons utiliser les m√©triques (23) associ√©es √† des d√©veloppeurs, celles-ci sont stock√©es dans le dossier <code> /content/drive/MyDrive/TP_GLIA/metrics_by_dev/ </code>. Chaque fichier de ce dossier est nomm√© en fonction de la version sur laquelle les m√©triques ont √©t√© extraites. Nous allons donc it√©rer sur la **liste de ces fichiers ordonn√©e par ordre alphanum√©rique**. \n",
    "\n",
    "4. Pour chaque fichier CSV, l'ouvrir avec Pandas en tant que Dataframe via la fonction : <code> pd.read_csv </code> ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))\n",
    "\n",
    "3. Ces m√©triques sont √† l'√©tat \"brute\" dans les fichiers, c'est-√†-dire qu'elles ont des √©chelles et des unit√©s diff√©rentes. Le classifieur Random Forest que nous avons entrain√© lui, ne travaille qu'avec des variables comprises dans [-1;1]. Ici, il va donc falloir faire une mise √† l'√©chelle des variables √† l'aide d'un scaler de Scikit-Learn : <code> MinMaxScaler </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)). De plus, afin de r√©duire les √©carts de valeurs sur certaines variables nous allons appliquer un logarithme sur 11 de ces derni√®res √† l'aide de la fonction  <code> log_dataframe </code> de ce Notebook.\n",
    "\n",
    "5. Pr√©dire ensuite la cat√©gorie des d√©veloppeurs (`NSSE` (*Non-Senior Software Developper*) ou `SSE`(*Senior Software Developper*)) puis la stocker dans le dictionnaire <code> dict_classified_dev </code>. Faire un petit affichage √† l'aide print pour visualiser l'√©volution du nombre de d√©voloppeurs dans chaque cat√©gorie au fur et √† mesure des versions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3GlHJpJLIa1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dict_classified_dev = {'SSE' : [], 'NSSE' : []}\n",
    "list_versions = []\n",
    "\n",
    "#Placer la suite du code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "SRYonIa09ry_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HpoYvxPDeVo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3) Extraction du nombre total de lignes de code depuis les fichiers CSV üìÇ\n",
    "\n",
    "Nous avons class√© les d√©veloppeurs par cat√©gorie pour chaque version de BroadleafCommerce. \n",
    "L'√©tape suivante est d'extraire le nombre total de ligne de code pour chaque version de BroadleafCommerce. Pour cela chacun des fichiers tri√©s par ordre alphanum√©rique croissant doit √™tre ouvert avec Pandas. Vous devez ensuite faire la somme de la colonne \"`loc`\" des fichiers et l'ajouter √† la liste <code> loc_by_versions </code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kndzp-CDeVp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Liste o√π ajouter la somme des loc pour chaque version\n",
    "loc_by_versions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "n5Epn8lm93Ml",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix7N_HWIDeVq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4) Trac√© du graphique du nombre de d√©veloppeurs SSE et nombre de lignes de code par version de BroadleafCommerce „ÄΩ\n",
    "\n",
    "L'objectif ici est de tracer √† l'aide du package matplotlib ([documentation](https://matplotlib.org/stable/contents.html)) un graphique √† 3 axes comme montr√© dans la figure d'exemple ci-dessous. \n",
    "\n",
    "![√âvolution du nombre de d√©veloppeurs SSE vs LOC](https://github.com/qperez/TP-Master-MTP-GL-IA4GL/raw/main/plot_sse_vs_loc_by_version.png)\n",
    "\n",
    "En tra√ßant cette figure vous devriez observer une particularit√© commune aux deux courbes, faite part de cette observation dans la case textutelle ci-desssous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OfBvW7rDeVs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**‚ñ∂ üîé Observations :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU9v7Yv6DeVs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cr√©ation de l'objet figure et axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "#Cr√©ation d'un deuxi√®me axe Y \n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "hxIDPfw49zdY",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KPg85CoDeVt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5) Cr√©ation d'un estimateur du nombre de d√©veloppeurs exp√©riment√©s en fonction de la taille du projet (LoC) üßô\n",
    "\n",
    "\n",
    "Nous avons maintenant l'ensemble des donn√©es permettant de cr√©er un estimateur du nombre de d√©veloppeurs exp√©riment√©s en fonction du nombre de ligne de code du projet. \n",
    "Pour ce faire, nous allons mettre en oeuvre un estimateur bas√© sur une r√©gression lin√©aire : <code> LinearRegression </code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)). Cet estimateur utilise la m√©thode des moindres carr√©s afin d'ajuster une droite d'√©quation $ax+b+e$ o√π $a$ est le coefficient directeur, $b$ l'ordonn√©e √† l'origine et $e$ l'erreur li√©e aux moindres carr√©s. \n",
    "\n",
    "Pour cela nous allons : \n",
    "1. Cr√©er un objet LinearRegression et l'ajuster sur <code> X </code> et <code> y </code> √† l'aide de la m√©thode <code> fit </code>.\n",
    "2. Afficher le coefficient de r√©gression sur <code> X </code> et <code> y </code>.\n",
    "3. D√©terminer le coefficient de d√©termination lin√©aire avec la fonction <code> r2_score </code> ([documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)) qui mesure l'ajustement entre les pr√©diction du classifieur sur les donn√©es <code> X </code> par rapport aux sorties <code> y </code>, plus il proche de 1 meilleures sont les pr√©dictions. \n",
    "4. Pr√©dire le nombre de d√©veloppeurs exp√©riment√©s SSE pour 150000, 180000 et 200000 lignes de code. \n",
    "5. Tracer un graphique semblable √† la figure d'exemple ci-desssous :\n",
    "\n",
    "![](https://github.com/qperez/TP-Master-MTP-GL-IA4GL/raw/main/plot_sse_loc_prediction.png)\n",
    "\n",
    "Les points noirs sont les donn√©es d√©j√† connues √† savoir le nombre de d√©veloppeurs exp√©riment√©s et le nombre de lignes de code pour chaque version. Les point rouges correspondent aux trois valeurs pr√©dites pour 150000, 180000 et 200000 lignes. La droite bleu est la droite de r√©gression. Pour tracer ce graphique vous pouvez vous inspirer de cet [exemple Scikit-Learn ](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py). \n",
    "\n",
    "Voil√† vous √™tes maintenant capable de pr√©dire vos besoins en ressources humaines en fonction de la taille de votre projet :) ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdOr_YX4DeVt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Valeurs X et y √† utiliser pour cr√©er et √©valuer le r√©gresseur\n",
    "X = np.array(loc_by_versions).reshape(-1,1)\n",
    "y = np.array(dict_classified_dev[\"SSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "c_0K1ILH9vvv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6) Matrice de corr√©lation sur une version du projet üî¢\n",
    "\n",
    "Nous allons √©tudier les potentielles corr√©lations entre variables de qualit√© pour une version donn√©e du projet. En effet, des corr√©lations positives ou n√©gatives pourraient indiquer les facteurs qui font croitre ou d√©croitre la qualit√© du projet. Cela peut par la suite aider √† la compr√©hension des facteurs de r√©ussite/√©chec d'une version, de la complexit√© de sa maintenance ou encore des leviers (nombre de lignes de code, couplages, etc) sur lesquelles travailler pour am√©liorer la qualit√© du projet.\n",
    "\n",
    "Pour √©tudier ces corr√©lations, nous allons utiliser la version `broadleaf-6.1.0-GA` (fichier `class_broadleaf-6.1.0-GA.csv`) et la liste de m√©triques suivantes : \n",
    "\n",
    "* `cbo` : Coupling Between Objects ‚û° Mesure la d√©pendance d'une classe √† d'autres classes du projet en utilisant les d√©clarations d'attributs, les types de retour de m√©thode, les d√©clarations de variables, etc).\n",
    "* `loc` : Lines Of Code ‚û° Mesure le nombre de lignes de code de chaque fichier\n",
    "* `wmc` : Weight Method Class ou mesure de McCabe ‚û° Mesure la complexit√© cyclomatique (nombre de chemins d'ex√©cution possibles) dans les m√©thodes.\n",
    "* `dit` : Depth Inheritance Tree ‚û° Mesure la profondeur d'h√©ritage des classes.\n",
    "\n",
    "Vous allez devoir : \n",
    "\n",
    "*   Ouvrir le fichier CSV avec pandas\n",
    "*   Extraire un sous ensemble du dataset pour ne conserver que `'cbo','wmc','loc','dit'`\n",
    "*   Cr√©er une matrice de corr√©lation √† partir de l'API de pandas et plus particuli√®rement de la m√©thode `corr(...)` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)). **/!\\ La m√©thode de corr√©lation √† utiliser est Spearman**.\n",
    "*   Plotter la heatmap montrant les corr√©lations entre les variables avec la librairie Seaborn et la m√©thode `heatmap(...)` ([documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html)). N'oubliez pas de faire figurer les coefficients sur votre heatmap.\n",
    "\n",
    "Donner votre avis sur cette matrice de corr√©lation. Quel effet semble avoir la taille des fichiers les autres variables ? Que peut-on en d√©duire ? R√©pondez dans la case observations ci-dessous."
   ],
   "metadata": {
    "id": "sIegM-tiLLDU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**‚ñ∂ üîé Observations :**"
   ],
   "metadata": {
    "id": "hF183CzP_s4M",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Votre code ici\n"
   ],
   "metadata": {
    "id": "jmTi04NJLBFB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7) √âtude de la relation entre le fait d'√™tre d√©veloppeur exp√©riment√© et de d√©velopper plusieurs projets sur Github ‚ùì\n",
    "\n",
    "Une question que nous pouvons nous poser concernant des d√©veloppeurs exp√©riment√©s est: \n",
    "\n",
    "> Existe-t-il une relation ou non entre le fait de contribuer √† plusieurs projets et le fait d'√™tre exp√©riment√© ?\n",
    "\n",
    "Cette question pourrait se poser par exemple en entreprise pour d√©terminer si un d√©veloppeur a un int√©r√™t √† travailler sur diff√©rents projets afin de gagner en exp√©rience d'un point de vue quantitatif, ou si les d√©veloppeurs ayant formation particuli√®re sont de \"meilleurs d√©veloppeurs\". \n",
    "\n",
    "Pour r√©pondre √† cette question nous allons utiliser un outil math√©matique qui s'appelle le test du [khi-deux](https://fr.wikipedia.org/wiki/Loi_du_%CF%87%C2%B2). Ce test va permettre de tester la relation entre 2 variables cat√©gorielles (ici de le fait d'√™tre exp√©riment√© ou non et de participer ou non √† plusieurs projets sur Github). \n",
    "\n",
    "Pour cela il faut premi√®rement formuler deux hypoth√®ses statistiques :\n",
    "\n",
    "*   Une hypoth√®se $H_0$ dite \"hypoth√®se nulle\" ‚û° Formalise le fait que les variables sont ind√©pendantes  \n",
    "\n",
    "> $H_0$ : Il n'y a pas de relation entre le fait d'√™tre exp√©riment√© ou non et de participer ou non √† plusieurs projets sur Github.\n",
    "\n",
    "\n",
    "*   Une hypoth√®se $H_1$ dite \"hypoth√®se alternative\" ‚û° Formalise le fait que ces variables sont d√©pendantes l'une de l'autre.\n",
    "\n",
    "> $H_1$ : Il y a une relation entre le fait d'√™tre exp√©riment√© ou non et de participer ou non √† plusieurs projets sur Github.\n",
    "\n",
    "Puis calculer le khi-deux et sa $p$-value. Ces hypoth√®ses vont √™tre accept√©es ou rejet√©es en fonction d'un seuil de risque $\\alpha$ (g√©n√©ralement 0.05) et le $p$-value calcul√©e par lors du test du khi-deux. \n",
    "\n",
    "*   Si $p$ < $\\alpha$ => Rejet de l'hypoth√®se $H_0$ et acceptation de $H_1$\n",
    "*   Sinon rejet de l'hypoth√®se $H_1$ et acceptation de $H_0$\n",
    "\n",
    "Ainsi pour r√©aliser ce test il faut: \n",
    "\n",
    "*   Trouver les d√©veloppeurs appraissant plusieurs fois dans le fichier `/content/drive/MyDrive/TP_GLIA/dataset_dev_anonymized.csv`. Un d√©veloppeur \"dupliqu√©\" est un d√©veloppeur ayant m√™me nom (colonne`'name_without_spaces'`) et m√™me statut (colonne `'job'`) dans le dataset. Pour cela aidez-vous de la m√©thode `duplicated(...)` de pandas ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)). Cette m√©thode vous permettra de marquer chaque d√©veloppeur comme dupliqu√© ou non en rangeant cette valeur dans une nouvelle colonne du dataframe nomm√©e `'multi_project'`.\n",
    "*   Ne conserver que les colonnes `'name_without_spaces'`, `'multi_project'` et `'job'`\n",
    "*   Remplacer l'ensemble des √©tiquettes `'SA'` (*Software Architect*) de la colonne `'job'` par `'SSE'` (*Senior Software Engineer*).\n",
    "* Remplacer toutes les √©tiquettes diff√©rentes de  `'SSE'` (*Senior Software Engineer*) par `'NSSE'` (*Non-Senior Software Engineer*)\n",
    "* Cr√©er une table de contingence en faisant un `pivot_table(..., aggfunc=len)` sur le dataset ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html)) \n",
    "* Printer la table de contingence \n",
    "* Calculer le khi-deux √† l'aide la m√©thode `chi2_contingency(...)` ([documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)) de la biblioth√®que SciPy \n",
    "* Printer les valeur calcul√©es par la m√©thode puis r√©pondez dans la case observations plus bas quelle hypoth√®se nous pouvons accepter avec un risque $\\alpha = 0.05$. Donnez √©galement la valeur de $p$-value\n",
    "\n"
   ],
   "metadata": {
    "id": "TrWrmKm5AOcy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**‚ñ∂ üîé Observations :**"
   ],
   "metadata": {
    "id": "E4Lb3z1HDo0H",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "#Votre code ici\n"
   ],
   "metadata": {
    "id": "dVRD8hQRAoSt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_pl6KJxDeVv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Bonus (Pas dans le TP)\n",
    "\n",
    "Jusque l√† nous avons utilis√© un classifieur Random Forest d√©j√† entrain√© puis sauvegard√© au format Pickle (s√©rialisation). Dans le bloc de code ci-dessous vous trouverez le code qui a permis la cr√©ation de ce classifieur. \n",
    "\n",
    "Ce code est d√©coup√© en plusieurs parties:\n",
    "\n",
    "* Ouverture du CSV contenant les d√©veloppeurs et leurs m√©triques avec Pandas\n",
    "* Suppresssion des colonnes non utilis√©es pour la classification\n",
    "* Transformation des variables (logarithme et mise √† l'√©chelle)\n",
    "* Cr√©ation de l'objet permettant de g√©n√©rer des donn√©es synth√©tiques. Les donn√©es synth√©tiques permettent de contrebalancer le fait que nous n'ayons que peu de donn√©es dans la classe des d√©veloppeurs exp√©riment√©s. \n",
    "* Cr√©ation du classifieur ici un random forest\n",
    "* √âvaluation du classifieur via 4-fold stratifi√© ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold))\n",
    "* G√©n√©ration de donn√©es synth√©tiques sur l'ensemble du jeu de donn√©es puis entrainement du mod√®le\n",
    "* Sauvegarde du mod√®le au format pickle\n",
    "\n",
    "Vous pouvez modifier plusieurs choses qui vont influer sur la qualit√© de votre classifieur :  \n",
    "- Les variables utilis√©es. Nous utilisons ici 23 m√©triques. Vous pouvez en supprimer dans le dataframe Pandas et constater l'effet. \n",
    "- Le scaler utilis√©, ici un MinMax pour mettre les variables dans l'intervalle [-1,1] ([documentation sur les types de scaler](https://www.datacorner.fr/feature-scaling/))\n",
    "- Le type de classifieur utilis√© (ici Random Forest) et ses param√®tres. Vous pouvez choisir un autre classifieur parmis ceux fournis par le package Scikit Learn ([documentation](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py))\n",
    "- L'utilisation ou non de la g√©n√©ration de donn√©es synth√©tiques. \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "G_gVmpihDeVv"
   },
   "source": [
    "Returns labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "cFm8-7wpDeVw"
   },
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    df.loc[df['job'] == \"SA\", 'job'] = \"SSE\"\n",
    "    df.loc[df['job'] != \"SSE\", 'job'] = \"NSSE\"\n",
    "\n",
    "    return df[\"job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "hW9fTu4bDeVw"
   },
   "source": [
    "Scales data according to the scaler given as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Yq5udrFeDeVx"
   },
   "outputs": [],
   "source": [
    "def scaling(scaler, X):\n",
    "    return scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "2R9D48NfDeVx"
   },
   "source": [
    "Creates synthetic data with original data using smote method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SfYot5VNDeVz"
   },
   "outputs": [],
   "source": [
    "def create_synthetic_data(smote, X_scaled, y):\n",
    "    return smote.fit_resample(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9r6IR-dfDeVz"
   },
   "source": [
    "Train the classifier with synthetic data an create a classification report on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "N2Q28HhGDeV0"
   },
   "outputs": [],
   "source": [
    "def train_and_classification_report(classifier, X_synthetic, y_synthetic, X_scaled, y):\n",
    "    classifier.fit(X_synthetic, y_synthetic)\n",
    "    print(classification_report(y, classifier.predict(X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wFUXxBnODeV0"
   },
   "outputs": [],
   "source": [
    "def stratifiedKFold_scoring(classifier, X_scaled, y, smote = None):\n",
    "    kf = StratifiedKFold(n_splits=4, shuffle=False)#, random_state=0)\n",
    "    print(\"===> Start kfold <===\")\n",
    "    scores = {\"F1\": {\"values\" : []}, \"Recall\": {\"values\" : []},\n",
    "              \"Precision\": {\"values\" : []}, \"Balanced\\nAccuracy\" : {\"values\" : []}}\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X_scaled, y), 1):\n",
    "        print(\"=> Fold : \",fold)\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train = X_scaled[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X_scaled[test_index]\n",
    "        y_test = y[test_index]\n",
    "\n",
    "        if smote is not None:\n",
    "            X_train_synthetic, y_train_synthetic = smote.fit_resample(X_train, y_train)\n",
    "            classifier.fit(X_train_synthetic, y_train_synthetic)\n",
    "        else:\n",
    "            classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        recall = recall_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        precision = precision_score(y_test, y_pred, pos_label=\"SSE\")\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        scores[\"F1\"][\"values\"].append(f1)\n",
    "        scores[\"Recall\"][\"values\"].append(recall)\n",
    "        scores[\"Precision\"][\"values\"].append(precision)\n",
    "        scores[\"Balanced\\nAccuracy\"][\"values\"].append(accuracy)\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key][\"values\"] = np.array(scores[key][\"values\"])\n",
    "        scores[key][\"mean\"] = np.mean(scores[key][\"values\"])\n",
    "        scores[key][\"std\"] = np.std(scores[key][\"values\"])\n",
    "        scores[key][\"ci95\"] = np.std(scores[key][\"values\"]) * 2\n",
    "\n",
    "        print(key, \"mean :%0.4f\" % scores[key][\"mean\"])\n",
    "        print(key, \"std : %0.4f\" % scores[key][\"std\"])\n",
    "        print(key, \"95%% Confidence Interval +/- %0.4f\" % (scores[key][\"ci95\"]))\n",
    "        print()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "IYY26QtUDeV1",
    "outputId": "4c4634e7-c951-4a4b-8fb9-1cbcf4ab9f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start kfold <===\n",
      "=> Fold :  1\n",
      "=> Fold :  2\n",
      "=> Fold :  3\n",
      "=> Fold :  4\n",
      "F1 mean :0.7689\n",
      "F1 std : 0.0263\n",
      "F1 95% Confidence Interval +/- 0.0525\n",
      "\n",
      "Recall mean :0.7538\n",
      "Recall std : 0.0800\n",
      "Recall 95% Confidence Interval +/- 0.1601\n",
      "\n",
      "Precision mean :0.7937\n",
      "Precision std : 0.0414\n",
      "Precision 95% Confidence Interval +/- 0.0828\n",
      "\n",
      "Balanced\n",
      "Accuracy mean :0.8603\n",
      "Balanced\n",
      "Accuracy std : 0.0343\n",
      "Balanced\n",
      "Accuracy 95% Confidence Interval +/- 0.0687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/TP_GLIA/dataset_dev_anonymized.csv\")\n",
    "y = get_labels(df)\n",
    "\n",
    "delete_unused_columns(df)\n",
    "\n",
    "log_dataframe(df)\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "X = df\n",
    "X_scaled = scaling(scaler, X)\n",
    "\n",
    "#Instanciation du g√©n√©rateur de donn√©es synth√©tiques √† l'aide de la m√©thode k-means SMOTE\n",
    "smote = KMeansSMOTE(sampling_strategy='minority', random_state=9090)\n",
    "#Cr√©ation du classifieur RF\n",
    "classifier = RandomForestClassifier(criterion='gini', max_depth=None, max_features='log2', n_estimators=75, random_state=0)\n",
    "\n",
    "#√âvaluation du classifieur √† l'aide d'un 4-fold stratifi√©\n",
    "stratifiedKFold_scoring(classifier, X_scaled, y, smote = smote)\n",
    "\n",
    "#G√©n√©ration de donn√©es synth√©tiques sur l'ensemble des donn√©es\n",
    "X_synthetic, y_synthetic = smote.fit_resample(X_scaled, y)\n",
    "#Entrainement du classifieur sur les donn√©es synth√©tiques\n",
    "classifier.fit(X_synthetic, y_synthetic)\n",
    "#Sauvegarde du classifieur (s√©rialisation) \n",
    "pickle.dump(classifier, open(\"/content/drive/MyDrive/TP_GLIA/classifier_rf.pkl\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b972025ffaeb9fad2e6c47485e66bc7f129e1b41ab4934c78195a6e21efd40ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}